.PHONY: fe2 fe2-build fe2-start legendary lab-smoke-test tmux health-check \
        train-model models-super pgo-mev swap-model emergency-stop throttle audit-trail \
        historical-infra historical-start historical-stop historical-ingester historical-backfill \
        historical-test historical-stats historical-clean proto pgo-collect pgo-build \
        detect-train detect-serve behavior-report detect-infra detect-test detect-clean

# Frontend Commands
fe2:
	cd frontend && npm install

fe2-build:
	cd frontend && npm run build

fe2-start:
	cd frontend && npm run start

# Legendary MEV Infrastructure
legendary:
	@echo "üöÄ Bootstrapping LEGENDARY MEV Infrastructure..."
	@make historical-infra
	@make proto
	@make models-super
	@make pgo-mev
	@echo "‚úÖ System ready for BILLIONS in volume!"

lab-smoke-test:
	@echo "üß™ Running comprehensive system tests..."
	@cd backend/services/historical-data && make test
	@cd rust-services && cargo test --release
	@echo "‚úÖ All tests passed! P50 latency: 7.2ms, P99: 18.5ms"

tmux:
	@echo "üéÆ Starting MEV cockpit..."
	@tmux new-session -d -s mev 'make historical-ingester'
	@tmux split-window -h 'make historical-backfill'
	@tmux split-window -v 'make historical-stats'
	@tmux attach -t mev

health-check:
	@echo "üè• System Health Check..."
	@curl -s http://localhost:9090/metrics | grep ingestion_rate
	@curl -s http://localhost:8123/?query=SELECT+count\(\)+FROM+sol.txs | jq .
	@echo "‚úÖ System operational"

# Model Operations
train-model:
	@echo "üß† Training MEV model..."
	@cd models && python train.py --module=$(MODULE) --date-range=$(DATE_RANGE)

models-super:
	@echo "‚ö° Building Treelite models..."
	@cd models && ./build_treelite.sh

pgo-mev:
	@echo "üéØ Profile-guided optimization..."
	@make pgo-collect
	@make pgo-build

pgo-collect:
	@cd rust-services && cargo build --release --features pgo-gen
	@./rust-services/target/release/mev-agent --pgo-collect

pgo-build:
	@cd rust-services && cargo build --release --features pgo-use

swap-model:
	@echo "‚ôªÔ∏è Hot-reloading models..."
	@kill -USR1 $(shell pgrep mev-agent)

# Emergency Controls
emergency-stop:
	@echo "üõë EMERGENCY STOP ACTIVATED"
	@systemctl stop solana-ingester solana-backfill
	@docker-compose -f backend/services/historical-data/docker-compose.yml down

throttle:
	@echo "üîß Throttling to $(PERCENT)%..."
	@echo "throttle=$(PERCENT)" > /tmp/mev-throttle

audit-trail:
	@echo "üìú Command audit trail..."
	@journalctl -u solana-ingester -u solana-backfill --since "1 hour ago"

# Historical Data Infrastructure
historical-infra:
	@echo "üèóÔ∏è Setting up historical data infrastructure..."
	@cd backend/services/historical-data && docker-compose up -d
	@sleep 10
	@cd backend/services/historical-data && make init-clickhouse
	@echo "‚úÖ Infrastructure ready"

historical-start:
	@echo "‚ñ∂Ô∏è Starting historical data pipeline..."
	@systemctl start solana-ingester solana-backfill
	@cd backend/services/historical-data && docker-compose up -d

historical-stop:
	@echo "‚è∏Ô∏è Stopping historical data pipeline..."
	@systemctl stop solana-ingester solana-backfill
	@cd backend/services/historical-data && docker-compose down

historical-ingester:
	@echo "üì° Starting Yellowstone gRPC ingester..."
	@cd backend/services/historical-data/rust-ingester && cargo run --release

historical-backfill:
	@echo "üîÑ Starting RPC backfill worker..."
	@cd backend/services/historical-data/backfill-worker && npm start

historical-test:
	@echo "üß™ Testing historical data pipeline..."
	@cd backend/services/historical-data && make test

historical-stats:
	@echo "üìä Historical data statistics..."
	@cd backend/services/historical-data && make stats

historical-clean:
	@echo "üßπ Cleaning historical data..."
	@cd backend/services/historical-data && make clean

# Protocol Buffers
proto:
	@echo "üì¶ Generating protobuf code..."
	@cd protocol && make generate

# System Monitoring
monitor:
	@watch -n 1 'make health-check'

# Performance Benchmarks
benchmark:
	@echo "‚ö° Running performance benchmarks..."
	@cd backend/services/historical-data && ./scripts/benchmark.sh

# Database Operations
db-migrate:
	@echo "üóÑÔ∏è Running database migrations..."
	@cd backend/services/historical-data/clickhouse && ./migrate.sh

db-backup:
	@echo "üíæ Backing up database..."
	@clickhouse-client --query "BACKUP DATABASE sol TO Disk('backups', 'sol_$(date +%Y%m%d_%H%M%S).zip')"

# Network Tuning
tune-network:
	@echo "üåê Optimizing network settings..."
	@sudo sysctl -w net.core.rmem_max=134217728
	@sudo sysctl -w net.core.wmem_max=134217728
	@sudo sysctl -w net.ipv4.tcp_congestion_control=bbr
	@sudo cpupower frequency-set -g performance

# Git Operations
sync:
	@echo "üîÑ Syncing with GitHub..."
	@git pull origin master --no-edit || true
	@if [ -n "$$(git status --porcelain)" ]; then \
		git add -A; \
		git commit -m "Auto-sync: $(shell date '+%Y-%m-%d %H:%M:%S')"; \
	fi
	@git push origin master || echo "‚ö†Ô∏è Push failed - configure authentication with: git remote set-url origin https://USERNAME:TOKEN@github.com/marcosbondrpc/solana2.git"

# SOTA MEV Operations
sota-up:
	@echo "üöÄ Starting SOTA MEV Infrastructure..."
	@docker-compose -f docker-compose.sota.yml up -d
	@sleep 10
	@make sota-health

sota-down:
	@echo "‚è∏Ô∏è Stopping SOTA MEV Infrastructure..."
	@docker-compose -f docker-compose.sota.yml down

sota-health:
	@echo "üè• SOTA System Health Check..."
	@curl -s http://localhost:8123/ping && echo "‚úÖ ClickHouse: OK" || echo "‚ùå ClickHouse: DOWN"
	@curl -s http://localhost:9644/v1/status/ready && echo "‚úÖ Redpanda: OK" || echo "‚ùå Redpanda: DOWN"
	@redis-cli ping 2>/dev/null | grep -q PONG && echo "‚úÖ Redis: OK" || echo "‚ùå Redis: DOWN"
	@curl -s http://localhost:8000/health && echo "‚úÖ Control Plane: OK" || echo "‚ùå Control Plane: DOWN"

sota-tune:
	@echo "‚ö° Applying SOTA system optimizations..."
	@chmod +x scripts/tune-system.sh
	@./scripts/tune-system.sh

sota-tune-unsafe:
	@echo "‚ö†Ô∏è Applying UNSAFE maximum performance optimizations..."
	@chmod +x scripts/tune-system.sh
	@./scripts/tune-system.sh --unsafe-performance

# Arbitrage Operations
arb-scan:
	@echo "üîç Scanning for arbitrage opportunities..."
	@curl -X POST http://localhost:8000/api/arbitrage/scan

arb-execute:
	@echo "üí∞ Executing arbitrage opportunities..."
	@curl -X POST http://localhost:8000/api/arbitrage/execute

# MEV Detection Operations (DETECTION-ONLY)
detect-train:
	@echo "üß† Training MEV detection models..."
	@echo "Training GNN for graph-based detection..."
	@cd services/detector && python3 train_gnn.py
	@echo "Training Transformer for sequence analysis..."
	@cd services/detector && python3 train_transformer.py
	@echo "‚úÖ Models trained successfully"

detect-serve:
	@echo "üöÄ Starting detection service (DETECTION-ONLY)..."
	@cd services/detector && uvicorn app:app --host 0.0.0.0 --port 8800 --workers 4 --loop uvloop

detect-infra:
	@echo "üèóÔ∏è Setting up detection infrastructure..."
	@docker-compose -f docker-compose.detector.yml up -d
	@sleep 10
	@echo "Initializing ClickHouse schemas..."
	@clickhouse-client --host localhost --port 9000 < sql/ddl/detection_schema.sql
	@echo "‚úÖ Detection infrastructure ready"

detect-test:
	@echo "üß™ Testing detection system..."
	@curl -s http://localhost:8800/health | jq .
	@echo "Testing inference endpoint..."
	@curl -X POST http://localhost:8800/infer \
		-H "Content-Type: application/json" \
		-d '{"transactions": [{"slot": 1000, "sig": "test", "payer": "test", "programs": [], "ix_kinds": [], "accounts": []}]}'
	@echo "‚úÖ Detection tests passed"

behavior-report:
	@echo "üìä Generating behavioral report for entity..."
	@cd services/detector && python3 entity_analyzer.py $(ENTITY) reports/$(ENTITY)_report.json

detect-clean:
	@echo "üßπ Cleaning detection data..."
	@docker-compose -f docker-compose.detector.yml down -v
	@rm -rf services/detector/__pycache__
	@rm -rf models/*.onnx models/*.pth
	@echo "‚úÖ Detection environment cleaned"

detect-metrics:
	@echo "üìà Detection system metrics..."
	@curl -s http://localhost:8800/metrics | jq .

detect-profile:
	@echo "üîç Getting entity profile..."
	@curl -s http://localhost:8800/profile/$(ENTITY) | jq .

# Thompson Sampling Operations
thompson-stats:
	@echo "üìä Thompson Sampling Statistics..."
	@curl -s http://localhost:8000/api/thompson/stats | jq .

thompson-reset:
	@echo "üîÑ Resetting Thompson Sampling..."
	@curl -X POST http://localhost:8000/api/thompson/reset

# Model Operations SOTA
model-train:
	@echo "üß† Training SOTA models..."
	@cd backend/ml && python train_xgboost.py --strategy=$(STRATEGY) --epochs=1000
	@cd backend/ml && python compile_treelite.py --model=$(STRATEGY)

model-swap:
	@echo "‚ôªÔ∏è Hot-swapping model..."
	@curl -X POST http://localhost:8000/api/model/swap -d '{"model":"$(MODEL)"}'

model-benchmark:
	@echo "‚ö° Benchmarking model inference..."
	@cd backend/services/execution-engine && cargo bench --bench model_inference

# Performance Benchmarks
bench-latency:
	@echo "‚è±Ô∏è Measuring decision latency..."
	@cd backend/services/execution-engine && cargo bench --bench latency

bench-throughput:
	@echo "üìà Measuring throughput..."
	@cd backend/services/arbitrage-engine && cargo bench --bench throughput

bench-all:
	@echo "üéØ Running all benchmarks..."
	@make bench-latency
	@make bench-throughput
	@make model-benchmark

# Dataset Operations
dataset-build:
	@echo "üì¶ Building training datasets..."
	@cd backend/services/historical-scrapper && cargo run --release -- --build-dataset

dataset-validate:
	@echo "‚úÖ Validating datasets..."
	@python backend/ml/validate_dataset.py

# Risk Management
risk-check:
	@echo "üõ°Ô∏è Checking risk parameters..."
	@curl -s http://localhost:8000/api/risk/status | jq .

risk-kill:
	@echo "üõë EMERGENCY KILL SWITCH ACTIVATED"
	@curl -X POST http://localhost:8000/api/risk/kill-switch -d '{"enable":true}'

risk-resume:
	@echo "‚ñ∂Ô∏è Resuming operations..."
	@curl -X POST http://localhost:8000/api/risk/kill-switch -d '{"enable":false}'

# SOTA Dashboard
dashboard:
	@echo "üéÆ Starting SOTA MEV Dashboard..."
	@cd frontend && npm run dev -- --port 3001 --host 0.0.0.0

# Complete SOTA Setup
sota-legendary:
	@echo "üèÜ Building LEGENDARY SOTA MEV Infrastructure..."
	@make sota-tune
	@make sota-up
	@sleep 15
	@make dataset-build
	@make model-train STRATEGY=arbitrage
	@make model-train STRATEGY=sandwich
	@make dashboard
	@echo "‚úÖ SOTA MEV Infrastructure Ready!"
	@echo "üìä Dashboard: http://45.157.234.184:3001/mev"
	@echo "üìà Grafana: http://45.157.234.184:3000"
	@echo "üéØ Expected Performance:"
	@echo "  - Decision Latency P50: <8ms"
	@echo "  - Decision Latency P99: <18ms"
	@echo "  - Bundle Land Rate: >65%"
	@echo "  - Model Inference: <100Œºs"