version: '3.8'

services:
  # Node Metrics Service
  node-metrics:
    build:
      context: ./services/node-metrics
      dockerfile: Dockerfile
    container_name: mev-node-metrics
    ports:
      - "8081:8081"  # WebSocket port
      - "9090:9090"  # Prometheus metrics
    environment:
      - RPC_ENDPOINTS=${RPC_ENDPOINTS:-http://solana-rpc:8899}
      - WS_ENDPOINTS=${WS_ENDPOINTS:-ws://solana-rpc:8900}
      - GEYSER_ENDPOINTS=${GEYSER_ENDPOINTS:-grpc://geyser:10000}
      - JITO_ENDPOINTS=${JITO_ENDPOINTS:-grpc://jito:8008}
      - REDIS_URL=redis://redis:6390
      - CLICKHOUSE_URL=http://clickhouse:8123
      - WS_PORT=8081
      - METRICS_PORT=9090
      - HEALTH_CHECK_INTERVAL_MS=100
      - METRICS_COLLECTION_INTERVAL_MS=50
      - RUST_LOG=debug
    depends_on:
      - redis
      - clickhouse
    networks:
      - mev-network
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '2'
          memory: 2G

  # Data Scrapper Service
  data-scrapper:
    build:
      context: ./services/data-scrapper
      dockerfile: Dockerfile
    container_name: mev-data-scrapper
    ports:
      - "8082:8082"  # API port
    environment:
      - RPC_ENDPOINT=${RPC_ENDPOINT:-https://api.mainnet-beta.solana.com}
      - API_PORT=8082
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=solana_data
      - REDIS_URL=redis://redis:6390
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC_PROGRESS=scrapper-progress
      - SCRAPPER_WORKERS=16
      - STORAGE_PATH=/data/scrapper
      - DATASET_PATH=/data/datasets
      - MODEL_PATH=/data/models
      - RUST_LOG=debug
    volumes:
      - scrapper-data:/data
    depends_on:
      - redis
      - clickhouse
      - kafka
    networks:
      - mev-network
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 8G
        reservations:
          cpus: '4'
          memory: 4G

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: mev-redis
    ports:
      - "6379:6379"
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - mev-network
    deploy:
      resources:
        limits:
          memory: 2G

  # ClickHouse for data storage
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: mev-clickhouse
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native protocol
    environment:
      - CLICKHOUSE_DB=solana_data
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - clickhouse-data:/var/lib/clickhouse
      - ./infrastructure/clickhouse/config.xml:/etc/clickhouse-server/config.xml:ro
      - ./infrastructure/clickhouse/users.xml:/etc/clickhouse-server/users.xml:ro
    networks:
      - mev-network
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

  # Kafka for streaming
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: mev-kafka
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_JMX_PORT=9101
      - KAFKA_JMX_HOSTNAME=localhost
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_NODE_ID=1
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:29093
      - KAFKA_LISTENERS=PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LOG_DIRS=/tmp/kraft-combined-logs
      - CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - mev-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: mev-prometheus
    ports:
      - "9091:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - mev-network
    deploy:
      resources:
        limits:
          memory: 1G

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: mev-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./infrastructure/grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
    networks:
      - mev-network
    deploy:
      resources:
        limits:
          memory: 512M

volumes:
  redis-data:
  clickhouse-data:
  kafka-data:
  prometheus-data:
  grafana-data:
  scrapper-data:

networks:
  mev-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16