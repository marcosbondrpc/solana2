# ML Pipeline Configuration for MEV Arbitrage Detection

preprocessing:
  # Feature Engineering
  create_interaction_features: true
  create_lag_features: true
  create_rolling_features: true
  lag_periods: [1, 2, 3, 5, 10, 20, 50]
  rolling_windows: [3, 5, 10, 20, 50, 100]
  
  # Normalization
  numerical_scaler: robust  # Options: standard, robust, minmax
  categorical_encoder: target  # Options: onehot, target, catboost
  
  # Imputation
  numerical_imputer: knn  # Options: mean, median, knn, iterative
  categorical_imputer: mode  # Options: mode, constant
  
  # Outlier Detection
  outlier_method: isolation_forest  # Options: isolation_forest, lof, zscore
  outlier_threshold: 0.01
  
  # Feature Selection
  feature_selection_method: mutual_info  # Options: mutual_info, chi2, anova
  n_features_to_select: 50
  
  # Performance
  use_gpu: true
  cache_preprocessed: true
  cache_ttl: 300
  n_jobs: -1

training:
  # Models to Train
  models_to_train:
    - random_forest
    - xgboost
    - lightgbm
    - catboost
    - lstm
    - transformer
    - ensemble
  
  # Ensemble Configuration
  enable_ensemble: true
  ensemble_method: stacking  # Options: voting, stacking, blending
  
  # Hyperparameter Optimization
  enable_hyperopt: true
  n_trials: 100
  hyperopt_timeout: 3600
  
  # Training Parameters
  test_size: 0.2
  n_splits: 5
  random_state: 42
  early_stopping_rounds: 50
  
  # Performance Targets
  target_accuracy: 0.95
  target_precision: 0.90
  target_recall: 0.85
  max_inference_time_ms: 10.0
  
  # GPU Settings
  use_gpu: true
  gpu_device: 0
  
  # Model Persistence
  save_models: true
  model_save_path: /home/kidgordones/0solana/node/arbitrage-data-capture/ml-pipeline/models/

monitoring:
  # Drift Detection
  drift_detection_method: ks  # Options: ks, mmd, chi2, tabular
  drift_threshold: 0.05
  drift_window_size: 1000
  reference_window_size: 10000
  
  # Performance Monitoring
  performance_window: 1000
  alert_thresholds:
    accuracy: 0.90
    precision: 0.85
    recall: 0.85
    f1: 0.85
    latency_ms: 15.0
  
  # Retraining Triggers
  auto_retrain: true
  retrain_on_drift: true
  retrain_on_performance_drop: true
  retrain_schedule: daily  # Options: hourly, daily, weekly
  min_samples_for_retrain: 10000
  
  # Alerting
  enable_alerts: true
  alert_channels:
    - prometheus
    - slack
    - email
  
  # Monitoring Intervals
  monitor_interval_seconds: 60
  metric_aggregation_window: 300

serving:
  # API Configuration
  host: 0.0.0.0
  port: 8000
  workers: 4
  
  # Performance Settings
  max_batch_size: 1000
  timeout_seconds: 30
  
  # Caching
  enable_cache: true
  cache_ttl_seconds: 60
  
  # Rate Limiting
  rate_limit_enabled: true
  rate_limit_requests: 10000
  rate_limit_window: 60

infrastructure:
  # ClickHouse
  clickhouse_host: localhost
  clickhouse_port: 9000
  clickhouse_database: arbitrage
  clickhouse_table: opportunities
  
  # Redis
  redis_host: localhost
  redis_port: 6379
  redis_db: 0
  redis_password: null
  
  # Kafka
  kafka_bootstrap_servers: localhost:9092
  kafka_topics:
    input: arbitrage_opportunities
    predictions: predictions
    alerts: model_alerts
  
  # Prometheus
  prometheus_port: 9090
  
  # Grafana
  grafana_url: http://localhost:3000
  grafana_api_key: null

performance_requirements:
  # Throughput
  min_predictions_per_second: 100000
  
  # Latency
  p50_latency_ms: 5
  p95_latency_ms: 10
  p99_latency_ms: 15
  
  # Accuracy
  min_accuracy: 0.95
  min_precision: 0.90
  min_recall: 0.85
  
  # Availability
  uptime_target: 0.999  # 99.9%
  
  # Resource Limits
  max_memory_gb: 32
  max_cpu_cores: 16
  
  # Scaling
  auto_scale: true
  min_replicas: 2
  max_replicas: 10
  target_cpu_utilization: 70